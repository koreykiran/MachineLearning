{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    " \\newcommand{\\wv}{\\mathbf{w}}\n",
    " \\newcommand{\\Chi}{\\mathcal{X}}\n",
    " \\newcommand{\\R}{\\rm I\\!R}\n",
    " \\newcommand{\\sign}{\\text{sign}}\n",
    "$\n",
    "\n",
    "# Linear Model\n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "## ITCS 6156/8156:  Machine Learning \n",
    "\n",
    "\n",
    "### Spring 2018\n",
    "\n",
    "### Minwoo \"Jake\" Lee\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quiz : PollEV.com/mjlee\n",
    "\n",
    "- Syllabus and Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Data Flow \n",
    "\n",
    "- Raw Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Preprocessing\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Algorithm Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Process \n",
    "\n",
    "<img src=\"https://webpages.uncc.edu/mlee173/teach/itcs6156/images/class/ml_process.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Supervised Learning\n",
    "\n",
    "### Linear Model \n",
    "\n",
    "- linear combination of input $\\xv$ and weight $\\wv$, so dot product\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  f(\\xv; \\wv) &= \\wv^\\top \\xv = \\sum_0^D w_i x_i \\\\\n",
    "     &= w_0 x_0 + w_1 x_1 + \\cdots + w_D x_D\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Liear Model? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Stable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Avoid Overfitting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Scalable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dot product\n",
    "\n",
    "- inner product\n",
    "- Geometric interpretation: angle between two vectors\n",
    "\n",
    "$$\n",
    "    \\wv^\\top \\xv = \\| \\wv \\| \\| \\xv \\| \\cos(\\theta),\n",
    "$$\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/3/3e/Dot_Product.svg)\n",
    "<center>(from wikipedia)</center>\n",
    "\n",
    "- What is $ X^\\top X $? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data with Labels\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\big\\{ (\\xv_i, y_i) \\big\\}_{i=1}^N  \\text{ where } \\xv_i \\in \\R^D\n",
    "$$\n",
    "\n",
    "- What are the labels for regressions? \n",
    "- What are the classification labels? ie. binary classification? \n",
    "- Then, what does the binary classification model look like? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$\\newcommand{\\xv}{\\mathbf{x}}\n",
    " \\newcommand{\\wv}{\\mathbf{w}}\n",
    " \\newcommand{\\Chi}{\\mathcal{X}}\n",
    " \\newcommand{\\R}{\\rm I\\!R}\n",
    " \\newcommand{\\sign}{\\text{sign}}\n",
    " \\newcommand{\\Tm}{\\mathbf{T}}\n",
    " \\newcommand{\\Xm}{\\mathbf{X}}\n",
    "$\n",
    "\n",
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Linear Regression\n",
    "\n",
    "- Application of linear model to the regression problem \n",
    "\n",
    "- Error function: \n",
    "    \n",
    "$$\n",
    "E(\\wv) = \\sum_{i=1}^N \\Big( f(\\xv_i; \\wv_i) - t_i \\Big)^2\n",
    "$$\n",
    "\n",
    "- Our estimation to be equal distance from all our target value $t_i$'s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Derivation\n",
    "\n",
    "$$\n",
    "\\wv^* = \\arg\\min_\\wv \\sum_{i=1}{N} \\Big( f(\\xv_i; \\wv) - t_i \\Big)^2\n",
    "$$\n",
    "\n",
    "\n",
    "- Review the notes\n",
    "\n",
    "$$\n",
    "\\wv^* = \\big(\\Xm^\\top \\Xm\\big)^{-1} \\Xm^\\top \\Tm\n",
    "$$\n",
    "\n",
    "- pseudo inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Can you convert the math into Python codes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Least Mean Squares\n",
    "\n",
    "- when the data is too large to store in memory, what can we do? \n",
    "- stream data... \n",
    "\n",
    "For one sample error $E_k$, we update the weights gradually as\n",
    "\n",
    "$$\n",
    "\\wv^{(k+1)} = \\wv^{(k)} - \\alpha \\nabla E_k.\n",
    "$$\n",
    "\n",
    "\n",
    "When the error is defined as\n",
    "\n",
    "$$\n",
    "E_k = \\Big( f(\\xv_k; \\wv^{(k)}) - t_k \\Big)^2, \n",
    "$$\n",
    "\n",
    "the gradient can be derived as \n",
    "\n",
    "$$\n",
    "\\nabla E_k = 2\\Big( {\\wv^{(k)}}^\\top \\xv_k - t_k \\Big) \\xv_k.\n",
    "$$\n",
    "\n",
    "Thus, the LMS update is defined as \n",
    "\n",
    "$$\n",
    "\\wv^{(k+1)} = \\wv^{(k)} - \\alpha \\Big( {\\wv^{(k)}}^\\top \\xv_k - t_k \\Big) \\xv_k.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Online Learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advantages of Online Learning \n",
    "\n",
    "- usally much faster than batch learning\n",
    "- often better solutions\n",
    "- model that changes over time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Batch Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advantages of Batch Learning \n",
    "\n",
    "- well-understood convergence conditions\n",
    "- many acceleration techniques\n",
    "- theoretical analysis are simpler "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Do NOT look at two extremes only!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini-batch Learning\n",
    "\n",
    "- combining two ideas\n",
    "- still hard to find the right mini-batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lab Activity \n",
    "\n",
    "### Normalization\n",
    "### Indicator Variables\n",
    "### \n",
    "\n",
    "### Partitioning Data \n",
    "\n",
    "- necessity to consider generalization of your model\n",
    "- measure for the performance with unseen data\n",
    "\n",
    "\n",
    "- training and testing partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PollEv.com/mjlee  (Attendance)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
