{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests,json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your niner number as the unique identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niner_number = 5301 #ENTER last four digits of you 800/801 number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start your game by using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'You can start the game !'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def startgame():\n",
    "    req = requests.get(\"https://agile-escarpment-74842.herokuapp.com/startGame/\"+str(niner_number))\n",
    "#     print(req.content)\n",
    "    return req.content\n",
    "startgame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###hit or stand or get observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action(self,action):\n",
    "    req = requests.get(\"https://agile-escarpment-74842.herokuapp.com/\"+str(action)+\"/\"+str(niner_number))\n",
    "    return req.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"total\":12,\"result\":\"Dealer Won, you Lost !\",\"dealerTotal\":20,\"Win\":false}'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action(\"stand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"cards\":[6,6],\"total\":12,\"dealerHand\":1}'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action(\"hit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 0, 'dealerHand': 1, 'usable': False}\n",
      "0 1 False\n"
     ]
    }
   ],
   "source": [
    "reply=action(\"getobsv\")\n",
    "rep=json.loads(reply.decode())\n",
    "print(rep)\n",
    "total=rep['total']\n",
    "dealerhand=rep['dealerHand']\n",
    "useable=rep['usable']\n",
    "print(total,dealerhand,useable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "\n",
    "def cmp(a, b):\n",
    "    return float(a > b) - float(a < b)\n",
    "\n",
    "# 1 = Ace, 2-10 = Number cards, Jack/Queen/King = 10\n",
    "deck = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 10, 10]\n",
    "\n",
    "\n",
    "def draw_card(np_random):\n",
    "    return int(np_random.choice(deck))\n",
    "\n",
    "\n",
    "def draw_hand(np_random):\n",
    "    return [draw_card(np_random), draw_card(np_random)]\n",
    "\n",
    "\n",
    "def usable_ace(hand):  # Does this hand have a usable ace?\n",
    "    return 1 in hand and sum(hand) + 10 <= 21\n",
    "\n",
    "\n",
    "def sum_hand(hand):  # Return current hand total\n",
    "    if usable_ace(hand):\n",
    "        return sum(hand) + 10\n",
    "    return sum(hand)\n",
    "\n",
    "\n",
    "def is_bust(hand):  # Is this hand a bust?\n",
    "    return sum_hand(hand) > 21\n",
    "\n",
    "\n",
    "def score(hand):  # What is the score of this hand (0 if bust)\n",
    "    return 0 if is_bust(hand) else sum_hand(hand)\n",
    "\n",
    "\n",
    "def is_natural(hand):  # Is this hand a natural blackjack?\n",
    "    return sorted(hand) == [1, 10]\n",
    "\n",
    "\n",
    "class BlackjackEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Taken from Open AI Gym and modified to display the sum of delers hand instead of just first card\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, natural=False):\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Tuple((\n",
    "            spaces.Discrete(32),\n",
    "            spaces.Discrete(11),\n",
    "            spaces.Discrete(2)))\n",
    "        self.seed()\n",
    "\n",
    "        self.natural = natural\n",
    "        # Start the first game\n",
    "        self.reset()\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        if action:  # hit: add a card to players hand and return\n",
    "            self.player.append(draw_card(self.np_random))\n",
    "            if is_bust(self.player):\n",
    "                done = True\n",
    "                reward = -1\n",
    "            else:\n",
    "                done = False\n",
    "                reward = 0\n",
    "        else:  # stick: play out the dealers hand, and score\n",
    "            done = True\n",
    "            while sum_hand(self.dealer) < 17:\n",
    "                self.dealer.append(draw_card(self.np_random))\n",
    "            reward = cmp(score(self.player), score(self.dealer))\n",
    "            if self.natural and is_natural(self.player) and reward == 1:\n",
    "                reward = 1.5\n",
    "        return self._get_obs(), reward, done, {sum_hand(self.dealer)}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return (sum_hand(self.player), self.dealer[0], usable_ace(self.player))\n",
    "\n",
    "    def reset(self):\n",
    "        self.dealer = draw_hand(self.np_random)\n",
    "        self.player = draw_hand(self.np_random)\n",
    "        return self._get_obs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Agent():\n",
    "    def __init__(self, env, epsilon=1.0, alpha=0.5, gamma=0.9, num_episodes_to_train=30000):\n",
    "        self.env = env\n",
    "\n",
    "        self.valid_actions = list(range(self.env.action_space.n))\n",
    "\n",
    "        # Set parameters of the learning agent\n",
    "        self.Q = dict()      # Q-table which will be a dictionary of tuples\n",
    "        self.epsilon = 0     # Random exploration factor\n",
    "        self.alpha = 0       # Learning factor\n",
    "        self.gamma = 0       # Discount factor- closer to 1 learns well into distant future\n",
    "        self.num_episodes_to_train = 0\n",
    "    \n",
    "    def init_decay(self,num_episodes_to_train):\n",
    "        self.num_episodes_to_train = num_episodes_to_train\n",
    "        self.small_decrement = (0.1 * self.epsilon) / (0.3 * self.num_episodes_to_train)\n",
    "        self.big_decrement = (0.8 * self.epsilon) / (0.4 * self.num_episodes_to_train)\n",
    "\n",
    "        self.num_episodes_to_train_left = self.num_episodes_to_train\n",
    "\n",
    "    def update_parameters(self):\n",
    "        if self.num_episodes_to_train_left > 0.7 * self.num_episodes_to_train:\n",
    "            self.epsilon -= self.small_decrement\n",
    "        elif self.num_episodes_to_train_left > 0.3 * self.num_episodes_to_train:\n",
    "            self.epsilon -= self.big_decrement\n",
    "        elif self.num_episodes_to_train_left > 0:\n",
    "            self.epsilon -= self.small_decrement\n",
    "        else:\n",
    "            self.epsilon = 0.0\n",
    "            self.alpha = 0.0\n",
    "\n",
    "        self.num_episodes_to_train_left -= 1\n",
    "\n",
    "    def create_Q_if_new_observation(self, observation):\n",
    "        if observation not in self.Q:\n",
    "            self.Q[observation] = dict((action, 0.0) for action in self.valid_actions)\n",
    "\n",
    "    def get_maxQ(self, observation):\n",
    "        self.create_Q_if_new_observation(observation)\n",
    "        return max(self.Q[observation].values())\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        self.create_Q_if_new_observation(observation)\n",
    "        if random.random() > self.epsilon:\n",
    "            maxQ = self.get_maxQ(observation)\n",
    "            action = random.choice([k for k in self.Q[observation].keys()\n",
    "                                    if self.Q[observation][k] == maxQ])\n",
    "        else:\n",
    "            action = random.choice(self.valid_actions)\n",
    "\n",
    "        self.update_parameters()\n",
    "\n",
    "        return action\n",
    "    \n",
    "    def get_action(self, observation):\n",
    "        self.create_Q_if_new_observation(observation)\n",
    "        maxQ = self.get_maxQ(observation)\n",
    "        return random.choice([k for k in self.Q[observation].keys()\n",
    "                                if self.Q[observation][k] == maxQ])\n",
    "\n",
    "\n",
    "    def learn(self, observation, action, reward, next_observation):\n",
    "        self.Q[observation][action] += self.alpha * (reward\n",
    "                                                     + (self.gamma * self.get_maxQ(next_observation))\n",
    "                                                     - self.Q[observation][action])\n",
    "        \n",
    "    def train(self, **params):\n",
    "        # parameters\n",
    "        self.gamma = params.pop('gamma', 0.2)\n",
    "        self.alpha = params.pop('alpha', 0.5)\n",
    "        self.epsilon= params.pop('epsilon', 1.0)\n",
    "        num_samples= params.pop('num_samples', 1000) \n",
    "        num_rounds= params.pop('num_rounds', 1000)\n",
    "        num_episodes_to_train = params.pop('num_episodes_to_train',800)\n",
    "        \n",
    "        self.init_decay(num_episodes_to_train)\n",
    "        \n",
    "        average_payouts = []\n",
    "\n",
    "        observation = self.env.reset()\n",
    "        for sample in range(num_samples):\n",
    "            round = 1\n",
    "            total_payout = 0\n",
    "            while round <= num_rounds:\n",
    "                action = self.choose_action(observation)\n",
    "                next_observation, payout, is_done, _ = self.env.step(action)\n",
    "                \n",
    "                self.learn(observation, action, payout, next_observation)\n",
    "                \n",
    "                total_payout += payout\n",
    "                observation = next_observation\n",
    "                if is_done:\n",
    "                    observation = self.env.reset()\n",
    "                    round += 1\n",
    "            average_payouts.append(total_payout)\n",
    "        return average_payouts\n",
    "    \n",
    "    def do_action(self,a):\n",
    "        req = requests.get(\"https://agile-escarpment-74842.herokuapp.com/\"+str(a)+\"/\"+str(niner_number))\n",
    "        return req.content\n",
    "    \n",
    "    def test(self,num_rounds):\n",
    "        rewards=[]\n",
    "        wins=0\n",
    "        loss=0\n",
    "        draw=0\n",
    "        for i in range(num_rounds):\n",
    "#             observation = self.env.reset()\n",
    "#             print(\"Inital State\",observation)\n",
    "            reply=self.do_action(\"getobsv\")\n",
    "            rep=json.loads(reply.decode())\n",
    "            total=rep['total']\n",
    "            dealerhand=rep['dealerHand']\n",
    "            useable=rep['usable']\n",
    "            print(\"Initial\",total,dealerhand,useable)\n",
    "            observation = (total, dealerhand, useable)\n",
    "            total_payout = 0\n",
    "            is_done =False\n",
    "            check =''\n",
    "            while not is_done:\n",
    "                action = self.get_action(observation)\n",
    "                if(action == 0):\n",
    "                    print(\"stand\")\n",
    "                    check = self.do_action('stand').decode(\"utf-8\")\n",
    "                else:\n",
    "                    print(\"Hit\")\n",
    "                    check = self.do_action('hit').decode(\"utf-8\")\n",
    "                \n",
    "#                 next_observation, payout, is_done, _ = self.env.step(action)\n",
    "#                 print(\"Next State\",next_observation, _)\n",
    "#                 total_payout += payout\n",
    "                \n",
    "                reply=self.do_action(\"getobsv\")\n",
    "                rep=json.loads(reply.decode())\n",
    "                total=rep['total']\n",
    "                dealerhand=rep['dealerHand']\n",
    "                useable=rep['usable']\n",
    "                print(\"after action\",total,dealerhand,useable)\n",
    "                observation = (total, dealerhand, useable)\n",
    "                \n",
    "                if \"Busted\" in check:\n",
    "                    print(\"Busted\",check)\n",
    "                    is_done = True;\n",
    "                    loss+=1\n",
    "                    break;\n",
    "                elif \"Win\" in check:\n",
    "                    b=json.loads(check)\n",
    "                    print(b)\n",
    "                    win=b['Win']\n",
    "                    if(win):\n",
    "                        wins+=1\n",
    "                    else:\n",
    "                        loss+=1\n",
    "                    is_done = True;\n",
    "                    break;\n",
    "            \n",
    "#             if(total_payout >0):\n",
    "#                 wins+=1\n",
    "#             elif(total_payout < 0):\n",
    "#                 loss+=1\n",
    "#             else:\n",
    "#                 draw+=1\n",
    "#             rewards.append(total_payout)\n",
    "        winPect = wins / num_rounds * 100\n",
    "        lossPect = loss / num_rounds * 100\n",
    "#         drawPect = (num_rounds- (wins+loss)) / num_rounds * 100\n",
    "        drawPect = 100 - (winPect + lossPect)\n",
    "        return  winPect, lossPect, drawPect \n",
    "    \n",
    "    def show_strategy(self):\n",
    "        list_players_hand = range(1, 22)\n",
    "        list_dealers_upcard = range(1, 11)\n",
    "        # Print headers to give more information about output\n",
    "        print (\"{:^10} | {:^51} | {:^51}\".format(\"Player's\",\"Dealer's upcard when ace is not usable\", \"Dealer's upcard when ace is usable\"))\n",
    "        print (\"{0:^10} | {1} | {1}\".format(\"Hand\", [str(upcard) if not upcard==1 else 'A' \n",
    "                                                        for upcard in list_dealers_upcard]))\n",
    "        for players_hand in list_players_hand:\n",
    "            actions_usable = []\n",
    "            actions_not_usable = []\n",
    "            for dealers_upcard in list_dealers_upcard:\n",
    "                observation = (players_hand, dealers_upcard, False)\n",
    "                actions_not_usable.append(self.readable_action(observation))\n",
    "                observation = (players_hand, dealers_upcard, True)\n",
    "                actions_usable.append(self.readable_action(observation))\n",
    "            print (\"{:>10} | {}  | {}\".format(players_hand, actions_not_usable, actions_usable))\n",
    "\n",
    "    def readable_action(self,observation):\n",
    "        \"\"\" \n",
    "        Pass observation to agent and get human readable action\n",
    "        H is hit, S is stick and '-' means the state is unseen and a random action is taken\n",
    "        \"\"\"\n",
    "        if observation not in self.Q:\n",
    "            action = \"-\"\n",
    "        else:\n",
    "            action = \"H\" if self.get_action(observation) else \"S\"    \n",
    "        return action\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 10 False\n",
      "13 10 False\n",
      "17 10 False\n",
      "b'{\"total\":17,\"result\":\"Dealer Won, you Lost !\",\"dealerTotal\":19,\"Win\":false}'\n",
      "did you win ?  False\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    \n",
    "    ##########CODE_TO_HIT##########\n",
    "    check=action(\"hit\").decode(\"utf-8\")\n",
    "    if \"Busted\" in check:\n",
    "        break;\n",
    "    ###############################\n",
    "    \n",
    "    \n",
    "    #############CODE_TO_GET_OBSERVATION############## \n",
    "    ##_Use the three variables to make decision to HIT or STAND\n",
    "    reply=action(\"getobsv\")\n",
    "    rep=json.loads(reply.decode())\n",
    "    total=rep['total']\n",
    "    dealerhand=rep['dealerHand']\n",
    "    useable=rep['usable']\n",
    "    print(total,dealerhand,useable)\n",
    "    ###########################\n",
    "    \n",
    "    \n",
    "            ###### WITHIN THIS LOOP IMPLEMENT LEARNING AND USE YOUR Policy/ Q TABLE TO DECIDE TO HIT OR STAND\n",
    "\n",
    "        \n",
    "        \n",
    "    while(total<17):## This condition is hardcoded.Do not do this. WRTIE your own condition to exit While loop to STAND\n",
    "                                \n",
    "            ### use total dealerhand and useable to decide next move\n",
    "            ### Just write break; if your decision is to stand    \n",
    "        \n",
    "        ##########CODE_TO_HIT##########\n",
    "        check=action(\"hit\").decode(\"utf-8\")\n",
    "        if \"Busted\" in check:\n",
    "            break;\n",
    "        ###############################\n",
    "         #############CODE_TO_GET_OBSERVATION############## \n",
    "        ##_Use the three variables to make decision to HIT or STAND\n",
    "        reply=action(\"getobsv\")\n",
    "        rep=json.loads(reply.decode())\n",
    "        total=rep['total']\n",
    "        dealerhand=rep['dealerHand']\n",
    "        useable=rep['usable']\n",
    "        print(total,dealerhand,useable)\n",
    "        ###########################\n",
    "        \n",
    "        \n",
    "   \n",
    "    #############CODE TO STAND################\n",
    "    a=action(\"stand\")\n",
    "    print(a)\n",
    "    b=json.loads(a.decode())\n",
    "    win=b['Win']\n",
    "    break;\n",
    "    ##########################################\n",
    "print (\"did you win ? \",win)\n",
    "useable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "envb = BlackjackEnv()\n",
    "agent = Agent(envb)\n",
    "num_rounds = 10000\n",
    "num_samples = 10000\n",
    "num_episodes_to_train = 0.8* num_rounds\n",
    "# epsilon=1.0, alpha=0.5, gamma=0.2\n",
    "average_payouts = agent.train(epsilon=1.0, alpha=0.1, gamma=0.1,num_rounds = num_rounds,num_samples = num_samples,num_episodes_to_train=num_episodes_to_train)\n",
    "# polt_result_blackJack(average_payouts,agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 0 1 False\n",
      "Hit\n",
      "after action 7 2 False\n",
      "stand\n",
      "after action 0 2 False\n",
      "Busted {\"total\":7,\"result\":\"Dealer Busted, you Won !\",\"dealerTotal\":25,\"Win\":true}\n",
      "Initial 0 2 False\n",
      "Hit\n",
      "after action 19 10 True\n",
      "Hit\n",
      "after action 0 0 True\n",
      "Busted {\"cards\":\"Busted\",\"total\":24}\n",
      "Initial 0 0 True\n",
      "stand\n",
      "after action 0 0 False\n",
      "Busted {\"total\":0,\"result\":\"Dealer Busted, you Won !\",\"dealerTotal\":23,\"Win\":true}\n",
      "Initial 0 0 False\n",
      "Hit\n",
      "after action 18 3 False\n",
      "stand\n",
      "after action 0 3 False\n",
      "Busted {\"total\":18,\"result\":\"Dealer Busted, you Won !\",\"dealerTotal\":26,\"Win\":true}\n",
      "Initial 0 3 False\n",
      "Hit\n",
      "after action 12 9 False\n",
      "Hit\n",
      "after action 21 9 False\n",
      "stand\n",
      "after action 0 9 False\n",
      "{'total': 21, 'result': 'Dealer Lost, you Won !', 'dealerTotal': 18, 'Win': True}\n",
      "Initial 0 9 False\n",
      "stand\n",
      "after action 0 9 False\n",
      "{'total': 0, 'result': 'Dealer Won, you Lost !', 'dealerTotal': 18, 'Win': False}\n",
      "Initial 0 9 False\n",
      "stand\n",
      "after action 0 9 False\n",
      "{'total': 0, 'result': 'Dealer Won, you Lost !', 'dealerTotal': 18, 'Win': False}\n",
      "Initial 0 9 False\n",
      "stand\n",
      "after action 0 9 False\n",
      "{'total': 0, 'result': 'Dealer Won, you Lost !', 'dealerTotal': 18, 'Win': False}\n",
      "Initial 0 9 False\n",
      "Hit\n",
      "after action 18 4 True\n",
      "Hit\n",
      "after action 0 0 True\n",
      "Busted {\"cards\":\"Busted\",\"total\":28}\n",
      "Initial 0 0 True\n",
      "stand\n",
      "after action 0 0 False\n",
      "{'total': 0, 'result': 'Dealer Won, you Lost !', 'dealerTotal': 19, 'Win': False}\n",
      "winP : 10.0 LossP : 90.0 DrawP : 0.0\n"
     ]
    }
   ],
   "source": [
    "wp,lp,dp = agent.test(10)\n",
    "print(\"winP :\",wp, \"LossP :\",lp,\"DrawP :\",dp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
